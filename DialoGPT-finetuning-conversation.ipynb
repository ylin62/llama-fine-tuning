{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a3ebcf37-2553-4cfc-a2c3-60fca3e87ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56342c4f-65c2-4688-8897-4d9f18c3a7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "81224e1a-4571-4898-8ce8-16270a90bf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/train.csv\").dropna(how=\"any\")\n",
    "\n",
    "train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4f0d5eb0-a632-44f4-8f47-be2fea8f15e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"If everyone thinks you're worthless, then maybe you need to find new people to hang out with.Seriously, the social context in which a person lives is a big influence in self-esteem.Otherwise, you can go round and round trying to understand why you're not worthless, then go back to the same crowd and be knocked down again.There are many inspirational messages you can find in social media. \\xa0Maybe read some of the ones which state that no person is worthless, and that everyone has a good purpose to their life.Also, since our culture is so saturated with the belief that if someone doesn't feel good about themselves that this is somehow terrible.Bad feelings are part of living. \\xa0They are the motivation to remove ourselves from situations and relationships which do us more harm than good.Bad feelings do feel terrible. \\xa0 Your feeling of worthlessness may be good in the sense of motivating you to find out that you are much better than your feelings today.\""
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3ef900-affd-4bb5-82c6-a2a191548a7d",
   "metadata": {},
   "source": [
    "### Load pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae70bac9-5db9-4e8c-afb9-31e85fcdbe3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"microsoft/DialoGPT-small\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7372b8c6-806b-4ea7-8924-6448f9b01b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9dfbfb97-4c19-48be-bb76-ddca655307df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer_function(examples):\n",
    "    inputs = tokenizer(examples[\"Context\"], truncation=True, padding=\"max_length\", max_length=128)\n",
    "    outputs = tokenizer(examples[\"Response\"], truncation=True, padding=\"max_length\", max_length=128)\n",
    "    return {\"input_ids\": inputs[\"input_ids\"], \"attention_mask\": inputs[\"attention_mask\"], \"labels\": outputs[\"input_ids\"]}\n",
    "\n",
    "train_tokenized = train_data.apply(tokenizer_function, axis=1)\n",
    "test_tokenized = test_data.apply(tokenizer_function, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "30a1a364-8e85-4e54-967d-56d1af72fa2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConversationDataset(Dataset):\n",
    "    def __init__(self, tokenized_data):\n",
    "        self.tokenized_data = tokenized_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tokenized_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.tokenized_data.iloc[idx]\n",
    "        return {k: torch.tensor(v, dtype=torch.long) for k, v in item.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8a4f627c-48a8-4b9a-9d6c-7cb044f63d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ConversationDataset(train_tokenized)\n",
    "test_dataset = ConversationDataset(test_tokenized)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4f780009-d83c-4088-b567-75a3b2293774",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "from transformers import get_scheduler\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "optimizer = AdamW(params=model.parameters(), lr=1e-4)\n",
    "num_epochs = 3\n",
    "num_training_steps = num_epochs * len(train_loader)\n",
    "\n",
    "scheduler = get_scheduler(\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6c3072ef-3c53-4325-83c2-3070bfef44bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "312a932184684225add409762de84907",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1 - Training:   0%|          | 0/351 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Average Training Loss = 5.7185\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76bfb7ae229a4c88999935ec95730aae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1 - Evaluation:   0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Average Evaluation Loss = 5.8267\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d5dec3548904d4182899738a4d7c413",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2 - Training:   0%|          | 0/351 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Average Training Loss = 5.7190\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "555c197cb0624abbb98747482b91986d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2 - Evaluation:   0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Average Evaluation Loss = 5.8267\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9fca9c8376a43f19d387f5be0c00c12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3 - Training:   0%|          | 0/351 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Average Training Loss = 5.7192\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ba714920b25457a8ef5a7d68ce78c76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3 - Evaluation:   0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Average Evaluation Loss = 5.8267\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1} - Training\")\n",
    "\n",
    "    for batch in progress_bar:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(input_ids=batch['input_ids'], attention_mask=batch['attention_mask'], labels=batch['labels'])\n",
    "        loss = outputs.loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "        progress_bar.set_postfix({'Training Loss': loss.item()})\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1}: Average Training Loss = {avg_train_loss:.4f}\")\n",
    "\n",
    "    # Evaluation phase\n",
    "    model.eval()\n",
    "    total_eval_loss = 0\n",
    "    progress_bar = tqdm(test_loader, desc=f\"Epoch {epoch+1} - Evaluation\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in progress_bar:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = model(input_ids=batch['input_ids'], attention_mask=batch['attention_mask'], labels=batch['labels'])\n",
    "            loss = outputs.loss\n",
    "\n",
    "            total_eval_loss += loss.item()\n",
    "            progress_bar.set_postfix({'Evaluation Loss': loss.item()})\n",
    "\n",
    "    avg_eval_loss = total_eval_loss / len(test_loader)\n",
    "    print(f\"Epoch {epoch+1}: Average Evaluation Loss = {avg_eval_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "08321a1e-d60e-49c1-885d-bd835ef515e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: I'm not feeling good you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "def chat_with_model(prompt):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    reply_ids = model.generate(**inputs, max_length=100, pad_token_id=tokenizer.eos_token_id)\n",
    "    reply = tokenizer.decode(reply_ids[0], skip_special_tokens=True)\n",
    "    return reply\n",
    "\n",
    "# Test the conversational agent\n",
    "user_input = \"I'm not feeling good\"\n",
    "response = chat_with_model(user_input)\n",
    "print(\"Model:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3c3785-e7dc-4b1f-ad84-e1e717e72b44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
