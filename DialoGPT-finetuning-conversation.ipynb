{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3ebcf37-2553-4cfc-a2c3-60fca3e87ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56342c4f-65c2-4688-8897-4d9f18c3a7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81224e1a-4571-4898-8ce8-16270a90bf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"data/train.csv\").dropna(how=\"any\")\n",
    "\n",
    "# train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "dataset = load_dataset(\"daily_dialog\")\n",
    "\n",
    "train_data = dataset[\"train\"]\n",
    "valid_data = dataset[\"validation\"]\n",
    "test_data = dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3ef900-affd-4bb5-82c6-a2a191548a7d",
   "metadata": {},
   "source": [
    "### Load pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae70bac9-5db9-4e8c-afb9-31e85fcdbe3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"microsoft/DialoGPT-small\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7372b8c6-806b-4ea7-8924-6448f9b01b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9dfbfb97-4c19-48be-bb76-ddca655307df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5384d24b31924ff8ab799df8ab604e6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11118 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    inputs = [\" \".join(utterance) for utterance in examples[\"dialog\"]]\n",
    "    tokenized_inputs = tokenizer(inputs, truncation=True, padding=\"max_length\", max_length=256)\n",
    "    return tokenized_inputs\n",
    "\n",
    "train_tokenized = train_data.map(tokenize_function, batched=True)\n",
    "valid_tokenized = valid_data.map(tokenize_function, batched=True)\n",
    "test_tokenized = test_data.map(tokenize_function, batched=True)\n",
    "\n",
    "train_tokenized.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"])\n",
    "valid_tokenized.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"])\n",
    "test_tokenized.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30a1a364-8e85-4e54-967d-56d1af72fa2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ConversationDataset(Dataset):\n",
    "#     def __init__(self, tokenized_data):\n",
    "#         self.tokenized_data = tokenized_data\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.tokenized_data)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         item = self.tokenized_data.iloc[idx]\n",
    "#         return {k: torch.tensor(v, dtype=torch.long) for k, v in item.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a4f627c-48a8-4b9a-9d6c-7cb044f63d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = ConversationDataset(train_tokenized)\n",
    "# test_dataset = ConversationDataset(test_tokenized)\n",
    "\n",
    "train_loader = DataLoader(train_tokenized, batch_size=8, shuffle=True)\n",
    "valid_loader = DataLoader(valid_tokenized, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f780009-d83c-4088-b567-75a3b2293774",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "from transformers import get_scheduler\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "optimizer = AdamW(params=model.parameters(), lr=5e-5)\n",
    "num_epochs = 3\n",
    "num_training_steps = num_epochs * len(train_loader)\n",
    "\n",
    "scheduler = get_scheduler(\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c3072ef-3c53-4325-83c2-3070bfef44bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e58b6f7fde2e448bb3736aae520cf8f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1 - Training:   0%|          | 0/1390 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Average Training Loss = 1.4017\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e89bead489b43cc8819cd90892e0c7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1 - Evaluation:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Average Evaluation Loss = 1.2397\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0a495b7a8cf4d7d9bfd19900b716b6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2 - Training:   0%|          | 0/1390 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Average Training Loss = 1.2162\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67d9cf116fe24b94979e0f4d9a631a5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2 - Evaluation:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Average Evaluation Loss = 1.2025\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abad8af114104dcd9b5b14e5ed4a6ef1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3 - Training:   0%|          | 0/1390 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Average Training Loss = 1.1660\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93f73299e6764ff4bd6b6a9974beb6bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3 - Evaluation:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Average Evaluation Loss = 1.1930\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1} - Training\")\n",
    "\n",
    "    for batch in progress_bar:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(input_ids=batch['input_ids'], attention_mask=batch['attention_mask'], labels=batch['input_ids'])\n",
    "        loss = outputs.loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "        progress_bar.set_postfix({'Training Loss': loss.item()})\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1}: Average Training Loss = {avg_train_loss:.4f}\")\n",
    "\n",
    "    # Evaluation phase\n",
    "    model.eval()\n",
    "    total_eval_loss = 0\n",
    "    progress_bar = tqdm(valid_loader, desc=f\"Epoch {epoch+1} - Evaluation\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in progress_bar:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = model(input_ids=batch['input_ids'], attention_mask=batch['attention_mask'], labels=batch['input_ids'])\n",
    "            loss = outputs.loss\n",
    "\n",
    "            total_eval_loss += loss.item()\n",
    "            progress_bar.set_postfix({'Evaluation Loss': loss.item()})\n",
    "\n",
    "    avg_eval_loss = total_eval_loss / len(valid_loader)\n",
    "    print(f\"Epoch {epoch+1}: Average Evaluation Loss = {avg_eval_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08321a1e-d60e-49c1-885d-bd835ef515e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: How are you!   Pretty good.You â€™ re so cute! How old is your sister? You look like she could be twenty-one. I think my older brother looks forty and thirty when he was a kid, but younger than that now at least 20 years later in life... maybe not quite as young though actually ; how about yourself if it were me to ask for some advice on the matter here first. What do they say then after seeing this photo of our daughter's face\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "def chat_with_model(prompt):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    reply_ids = model.generate(**inputs, \n",
    "                               max_length=100, \n",
    "                               pad_token_id=tokenizer.eos_token_id, \n",
    "                               eos_token_id=tokenizer.eos_token_id, \n",
    "                               do_sample=True, \n",
    "                               top_k=50, \n",
    "                               top_p=0.9, \n",
    "                               temperature=0.7,\n",
    "                               repetition_penalty=1.2)\n",
    "    reply = tokenizer.decode(reply_ids[0], skip_special_tokens=True)\n",
    "    return reply\n",
    "\n",
    "# Test the conversational agent\n",
    "user_input = \"How are you!\"\n",
    "response = chat_with_model(user_input)\n",
    "print(\"Model:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf0d81f-56a6-479f-ad5b-4f3122e02fd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
